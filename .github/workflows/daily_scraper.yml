name: Daily scraping

on: 
  schedule:
    - cron:  '10 03 * * *'

permissions:
  contents: write

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r $GITHUB_WORKSPACE/_resources/scraper_requirements.txt

    - name: Create year/month dirs if not existing
      run: |
        cd $GITHUB_WORKSPACE
        mkdir -p $(date --date="yesterday" '+%Y/%m')

    - name: Scrape the previous day publication and push to the repository
      run: |
        cd $GITHUB_WORKSPACE
        python $GITHUB_WORKSPACE/_resources/scraper.py -d yesterday
        git config user.name scraping-bot
        git config user.email github-actions@github.com
        git pull
        git add -A
        git commit -m "scraping bot - $(date --date="yesterday" '+%Y/%m/%d')"
        git push

    - name: Consolidate the full dataset
      run: |
        cd $GITHUB_WORKSPACE
        csvstack -n datefile --filenames 20**/**/**-**-****.csv | csvformat -U 1 > ./full_dataset/full.csv
        git config user.name scraping-bot
        git config user.email github-actions@github.com
        git pull
        git add -A
        git commit -m "fulldataset bot - $(date --date="yesterday" '+%Y/%m/%d')"
        git push
